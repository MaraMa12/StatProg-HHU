<!DOCTYPE html>
<html lang="en"><head>
<script src="Lecture_4_files/libs/clipboard/clipboard.min.js"></script>
<script src="Lecture_4_files/libs/quarto-html/tabby.min.js"></script>
<script src="Lecture_4_files/libs/quarto-html/popper.min.js"></script>
<script src="Lecture_4_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="Lecture_4_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Lecture_4_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="Lecture_4_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="Lecture_4_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <title>Lecture 4: Classification</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="Lecture_4_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="Lecture_4_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        background-color: #232629;
        color: #7a7c7d;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #7a7c7d;  padding-left: 4px; }
    div.sourceCode
      { color: #cfcfc2; background-color: #232629; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #cfcfc2; } /* Normal */
    code span.al { color: #95da4c; background-color: #4d1f24; font-weight: bold; } /* Alert */
    code span.an { color: #3f8058; } /* Annotation */
    code span.at { color: #2980b9; } /* Attribute */
    code span.bn { color: #f67400; } /* BaseN */
    code span.bu { color: #7f8c8d; } /* BuiltIn */
    code span.cf { color: #fdbc4b; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #3daee9; } /* Char */
    code span.cn { color: #27aeae; font-weight: bold; } /* Constant */
    code span.co { color: #7a7c7d; } /* Comment */
    code span.cv { color: #7f8c8d; } /* CommentVar */
    code span.do { color: #a43340; } /* Documentation */
    code span.dt { color: #2980b9; } /* DataType */
    code span.dv { color: #f67400; } /* DecVal */
    code span.er { color: #da4453; text-decoration: underline; } /* Error */
    code span.ex { color: #0099ff; font-weight: bold; } /* Extension */
    code span.fl { color: #f67400; } /* Float */
    code span.fu { color: #8e44ad; } /* Function */
    code span.im { color: #27ae60; } /* Import */
    code span.in { color: #c45b00; } /* Information */
    code span.kw { color: #cfcfc2; font-weight: bold; } /* Keyword */
    code span.op { color: #cfcfc2; } /* Operator */
    code span.ot { color: #27ae60; } /* Other */
    code span.pp { color: #27ae60; } /* Preprocessor */
    code span.re { color: #2980b9; background-color: #153042; } /* RegionMarker */
    code span.sc { color: #3daee9; } /* SpecialChar */
    code span.ss { color: #da4453; } /* SpecialString */
    code span.st { color: #f44f4f; } /* String */
    code span.va { color: #27aeae; } /* Variable */
    code span.vs { color: #da4453; } /* VerbatimString */
    code span.wa { color: #da4453; } /* Warning */
  </style>
  <link rel="stylesheet" href="Lecture_4_files/libs/revealjs/dist/theme/quarto.css">
  <link href="Lecture_4_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="Lecture_4_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="Lecture_4_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="Lecture_4_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="Lecture_4_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="Lecture_4_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="../shared_files/statprog_logo.jpg" data-background-position="98% 2%" data-background-size="15%" class="quarto-title-block center">
  <h1 class="title">Lecture 4: Classification</h1>
  <p class="subtitle">Topics in Econometrics and Data Science <br> Prof.&nbsp;Dr.&nbsp;Jannis Kück</p>

<div class="quarto-title-authors">
</div>

</section>
<section>
<section id="part-iv-machine-learning-classification" class="title-slide slide level1 center">
<h1>Part IV: Machine Learning, Classification</h1>
<p><span class="math inline">\(\newcommand{\E}{{\mathbb{E}}}\)</span> <span class="math inline">\(\newcommand{\N}{{\mathbb{N}}}\)</span> <span class="math inline">\(\newcommand{\R}{{\mathbb{R}}}\)</span></p>
<p><span class="math inline">\(\newcommand{\nto}{\xrightarrow[n\to\infty]{}}\)</span> <span class="math inline">\(\newcommand{\Dto}{\xrightarrow[]{\mathcal{D}}}\)</span> <span class="math inline">\(\newcommand{\Pto}{\xrightarrow[]{P}}\)</span> <span class="math inline">\(\newcommand{\asto}{\xrightarrow[]{a.s.}}\)</span> <span class="math inline">\(\newcommand{\Lto}{\xrightarrow[]{\mathcal{L}_2}}\)</span> <span class="math inline">\(\DeclareMathOperator{\rank}{rank}\)</span> <span class="math inline">\(\DeclareMathOperator{\sign}{sign}\)</span> <span class="math inline">\(\DeclareMathOperator{\logit}{logit}\)</span></p>
</section>
<section id="machine-learning" class="slide level2">
<h2>Machine Learning</h2>
<h4 id="classification">Classification</h4>
<ol type="1">
<li>Logistic Regression</li>
<li>Nearest Neighbors Classification</li>
<li>Support Vector Machines</li>
<li>Decision Trees</li>
<li>Random Forests</li>
</ol>
</section>
<section id="supervised-classification" class="slide level2">
<h2>Supervised Classification</h2>
<ul>
<li><p><strong>Goal:</strong> Predict the unknown label <span class="math inline">\(Y\)</span> of an observation of some features <span class="math inline">\(X\)</span>.</p></li>
<li><p><span class="math inline">\(Y\in \mathcal{Y}\)</span> where <span class="math inline">\(\mathcal{Y}= \{0,1\}\)</span> (binary classification) or <span class="math inline">\(\mathcal{Y}\subseteq\mathbb{N}\)</span>.</p></li>
<li><p><span class="math inline">\(X\in\mathcal{X}\)</span> where often <span class="math inline">\(\mathcal{X} = \R^p\)</span>.</p></li>
<li><p><strong>Classifier:</strong> We aim at building a classifier <span class="math inline">\(\hat{g}\)</span> with <span class="math display">\[\begin{align*}
\hat{g}:&amp;\mathcal{X}\to \mathcal{Y}\\
&amp;x\mapsto y
\end{align*}
\]</span></p></li>
</ul>
</section>
<section id="classification-examples" class="slide level2">
<h2>Classification Examples</h2>
<ul>
<li>Credit scoring: Predict loan reimbursement based on social/economics/health measurement
<ul>
<li><span class="math inline">\(X_i=(X_{i,1},X_{i,2},X_{i,3})\)</span> where
<ul>
<li><span class="math inline">\(X_{i,1} =\)</span> gross salary of ind. <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(X_{i,2} \in \{1,\dots,K\} =\)</span> socio-professional category of ind. <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(X_{i,3} = 1\)</span> if ind. <span class="math inline">\(i\)</span> already has an ongoing loan, <span class="math inline">\(0\)</span> otherwise.</li>
</ul></li>
<li><span class="math inline">\(\mathcal{X} = \R\times\{1,\dots,K\}\times\{0,1\}\)</span></li>
<li><span class="math inline">\(\mathcal{Y} = \{\)</span>“safe”,“risky”<span class="math inline">\(\}\)</span></li>
</ul></li>
</ul>
</section>
<section id="classification-examples-1" class="slide level2">
<h2>Classification Examples</h2>
<ul>
<li>Cancer prediction: Predict cancer grade (from <span class="math inline">\(1\)</span> to <span class="math inline">\(3\)</span>).
<ul>
<li><span class="math inline">\(X_i=(X_{i,1},\dots,X_{i,p})\)</span> where <span class="math inline">\(X_{i,j}\)</span> is the number of copies of chromosome segment <span class="math inline">\(j\)</span> in ind. <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(\mathcal{X} = \R^p\)</span></li>
<li><span class="math inline">\(\mathcal{Y} = \{1,2,3\}\)</span></li>
</ul></li>
</ul>
</section>
<section id="classification-1" class="slide level2">
<h2>Classification</h2>
<h4 id="example">Example</h4>
<div id="7dc9e709" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href=""></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href=""></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb1-3"><a href=""></a>n <span class="op">=</span> [<span class="dv">100</span>,<span class="dv">90</span>,<span class="dv">130</span>]</span>
<span id="cb1-4"><a href=""></a>Y <span class="op">=</span> np.append(np.append(np.zeros(n[<span class="dv">0</span>]),np.ones(n[<span class="dv">1</span>])),<span class="dv">2</span><span class="op">*</span>np.ones(n[<span class="dv">2</span>]))</span>
<span id="cb1-5"><a href=""></a></span>
<span id="cb1-6"><a href=""></a>X1 <span class="op">=</span> np.random.multivariate_normal([<span class="dv">0</span>,<span class="dv">0</span>], [[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>]], n[<span class="dv">0</span>])</span>
<span id="cb1-7"><a href=""></a>X2 <span class="op">=</span> np.random.multivariate_normal([<span class="dv">1</span>,<span class="op">-</span><span class="dv">2</span>], [[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>]], n[<span class="dv">1</span>])</span>
<span id="cb1-8"><a href=""></a>X3 <span class="op">=</span> np.random.multivariate_normal([<span class="dv">3</span>,<span class="dv">0</span>],[[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>]], n[<span class="dv">2</span>])</span>
<span id="cb1-9"><a href=""></a></span>
<span id="cb1-10"><a href=""></a>X <span class="op">=</span> np.concatenate((X1,X2,X3))</span>
<span id="cb1-11"><a href=""></a></span>
<span id="cb1-12"><a href=""></a><span class="co"># Construction of the test sample</span></span>
<span id="cb1-13"><a href=""></a>n_test <span class="op">=</span> [<span class="dv">100</span>,<span class="dv">90</span>,<span class="dv">130</span>]</span>
<span id="cb1-14"><a href=""></a>Y_test <span class="op">=</span> np.append(np.append(np.zeros(n_test[<span class="dv">0</span>]),np.ones(n_test[<span class="dv">1</span>])),<span class="dv">2</span><span class="op">*</span>np.ones(n_test[<span class="dv">2</span>]))</span>
<span id="cb1-15"><a href=""></a></span>
<span id="cb1-16"><a href=""></a>X1_test <span class="op">=</span> np.random.multivariate_normal([<span class="dv">0</span>,<span class="dv">0</span>], [[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>]], n_test[<span class="dv">0</span>])</span>
<span id="cb1-17"><a href=""></a>X2_test <span class="op">=</span> np.random.multivariate_normal([<span class="dv">1</span>,<span class="op">-</span><span class="dv">2</span>], [[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>]], n_test[<span class="dv">1</span>])</span>
<span id="cb1-18"><a href=""></a>X3_test <span class="op">=</span> np.random.multivariate_normal([<span class="dv">3</span>,<span class="dv">0</span>],[[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>]], n_test[<span class="dv">2</span>])</span>
<span id="cb1-19"><a href=""></a></span>
<span id="cb1-20"><a href=""></a>X_test <span class="op">=</span> np.concatenate((X1_test,X2_test,X3_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>

<img data-src="figures/Example_1.png" class="r-stretch"></section>
<section id="logistic-regression-logit" class="slide level2">
<h2>Logistic Regression (Logit)</h2>
<ul>
<li>We consider a binary classifier: <span class="math inline">\(Y\in\{0,1\}\)</span>.<br> The idea is that the target variable has the following conditional distribution <span class="math display">\[Y_i|X_i=x_i\sim \text{Bernoulli}(p_i)\]</span> where <span class="math display">\[p_i:=P(Y_i=1|X_i=x_i)\]</span> is assumed to have the following form: <span class="math display">\[p_i(\beta)=\frac{\exp\big(\beta_0+\sum\limits_{j=1}^p \beta_j x_{i,j}\big)}{1+\exp\big(\beta_0+\sum\limits_{j=1}^p \beta_j x_{i,j}\big)}\]</span></li>
</ul>
</section>
<section id="logistic-regression-logit-1" class="slide level2">
<h2>Logistic Regression (Logit)</h2>
<ul>
<li><p>This is equivalent to <span class="math display">\[\logit(p_i)=\beta_0+\sum\limits_{j=1}^p \beta_j x_{i,j}\]</span> where <span class="math display">\[\logit(p):=\log\Big(\frac{p}{1-p}\Big).\]</span></p></li>
<li><p>We estimate <span class="math inline">\(\beta\)</span> by maximizing the (conditional) likelihood function <span class="math display">\[\hat{\beta}=\arg\max\limits_{\beta\in\R^{p+1}}\mathcal{L}(\beta)=\arg\max\limits_{\beta\in\R^{p+1}}\prod\limits_{i=1}^n p_i(\beta)^{Y_i}(1-p_i(\beta))^{1-Y_i}.\]</span></p></li>
</ul>
</section>
<section id="logistic-regression-logit-2" class="slide level2">
<h2>Logistic Regression (Logit)</h2>
<ul>
<li>The prediction rule is obtained by maximizing the probability over the outcomes <span class="math display">\[\hat{g}(x)=\begin{cases}1\quad p(\hat{\beta})&gt;\frac{1}{2}\\
0\quad p(\hat{\beta})\le\frac{1}{2}\end{cases}\]</span> where <span class="math display">\[p(\hat{\beta})=\frac{\exp\big(\hat{\beta}_0+\sum\limits_{j=1}^p \hat{\beta}_j x_{j}\big)}{1+\exp\big(\hat{\beta}_0+\sum\limits_{j=1}^p \hat{\beta}_j x_{j}\big)}
\]</span></li>
</ul>
<!-- * The generalization to multi-valued outcomes is straight forward (combining several binary classifiers). -->
</section>
<section id="logistic-regression-logit-3" class="slide level2">
<h2>Logistic Regression (Logit)</h2>
<div id="e0b47771" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href=""></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb2-2"><a href=""></a>logisticRegr <span class="op">=</span> LogisticRegression(penalty <span class="op">=</span> <span class="st">'l2'</span> ,solver <span class="op">=</span> <span class="st">'liblinear'</span>, multi_class <span class="op">=</span> <span class="st">'auto'</span>)</span>
<span id="cb2-3"><a href=""></a>model <span class="op">=</span> logisticRegr.fit(X, Y)</span>
<span id="cb2-4"><a href=""></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, np.mean(np.equal(model.predict(X_test),Y_test)) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.8375</code></pre>
</div>
</div>

<img data-src="figures/Example_1_logistic.png" class="r-stretch"></section>
<section id="classification-2" class="slide level2">
<h2>Classification</h2>
<ul>
<li>There are many more ML methods for classification, e.g.,
<ul>
<li>Nearest Neighbors Classification,</li>
<li>Decision Trees,</li>
<li>Random Forests,</li>
<li>Gradient Boosting,</li>
<li>SVMs</li>
<li>etc.</li>
</ul></li>
</ul>
</section>
<section id="nearest-neighbors-classification" class="slide level2">
<h2>Nearest Neighbors Classification</h2>
<ul>
<li><p>The <span class="math inline">\(k\)</span>-nearest neighbor classification is a prediction rule which weights the <span class="math inline">\(k\)</span> nearest neighbors and performs the prediction due to a simple majority vote.</p></li>
<li><p>The distance of two points <span class="math inline">\(x=(x_1,\dots,x_p)\)</span> and <span class="math inline">\(x'=(x'_1,\dots,x'_p)\)</span> is measured with the euclidean distance <span class="math display">\[d(x,x')=\|x-x'\|_2=\Big(\sum\limits_{j=1}^n(x_j-x'_j)^2\Big)^{1/2}.\]</span> Given a sample <span class="math inline">\((Y_1,X_1),\dots,(Y_n,X_n)\)</span> and a point <span class="math inline">\(x\)</span> we can calculate the distance of each point to <span class="math inline">\(x\)</span> <span class="math display">\[d_i(x):=d(X_i,x).\]</span></p></li>
</ul>
</section>
<section id="nearest-neighbors-classification-1" class="slide level2">
<h2>Nearest Neighbors Classification</h2>
<ul>
<li><p>The set of indices of the <span class="math inline">\(k\)</span>-nearest neighbors of a point <span class="math inline">\(x\)</span> is defined as <span class="math display">\[\mathcal{N}(x,k):=\{i:d_{i}(x)\le d_{[k]}(x)\}\]</span> where <span class="math inline">\(d_{[k]}(x)\)</span> is the order statistic of the distances.</p></li>
<li><p>This implies we are able to assign a probability to each of the outcomes <span class="math inline">\(y_{k'}\)</span> <span class="math display">\[p_{k'}^{(x)}:= \sum\limits_{i\in\mathcal{N}(x,k)} w_i 1_{\{y_{k'}=Y_i\}}.\]</span></p></li>
</ul>
</section>
<section id="nearest-neighbors-classification-2" class="slide level2">
<h2>Nearest Neighbors Classification</h2>
<ul>
<li><p>The prediction rule is obtained by maximizing the probability over the outcomes <span class="math display">\[\hat{g}(x)=\arg\max\limits_{k'\in\{1,\dots,K\}}p_{k'}^{(x)}\]</span></p></li>
<li><p>Often the algorithm uses uniform weights <span class="math display">\[w_i =\frac{1}{k}\quad i\in \mathcal{N}(x,k)\]</span> or dependent on the distance <span class="math display">\[w_i=\frac{d_i(x)^{-1}}{\sum\limits_{j\in\mathcal{N}(x,k)}d_j(x)^{-1}}.\]</span></p></li>
</ul>
</section>
<section id="nearest-neighbors-classification-3" class="slide level2">
<h2>Nearest Neighbors Classification</h2>
<div id="42ec5a57" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href=""></a><span class="im">from</span> sklearn <span class="im">import</span> neighbors</span>
<span id="cb4-2"><a href=""></a>neighb <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors <span class="op">=</span> <span class="dv">20</span>, weights <span class="op">=</span> <span class="st">'uniform'</span>)</span>
<span id="cb4-3"><a href=""></a>model <span class="op">=</span> neighb.fit(X, Y)</span>
<span id="cb4-4"><a href=""></a></span>
<span id="cb4-5"><a href=""></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, np.mean(np.equal(model.predict(X_test),Y_test)) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.840625</code></pre>
</div>
</div>

<img data-src="figures/Example_1_kNN_uniform.png" class="r-stretch"></section>
<section id="nearest-neighbors-classification-4" class="slide level2">
<h2>Nearest Neighbors Classification</h2>
<div id="4da48671" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href=""></a><span class="im">from</span> sklearn <span class="im">import</span> neighbors</span>
<span id="cb6-2"><a href=""></a>neighb <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors <span class="op">=</span> <span class="dv">20</span>, weights <span class="op">=</span> <span class="st">'distance'</span>)</span>
<span id="cb6-3"><a href=""></a>model <span class="op">=</span> neighb.fit(X, Y)</span>
<span id="cb6-4"><a href=""></a></span>
<span id="cb6-5"><a href=""></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, np.mean(np.equal(model.predict(X_test),Y_test)) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.828125</code></pre>
</div>
</div>

<img data-src="figures/Example_1_kNN_distance.png" class="r-stretch"></section>
<section id="support-vector-machines" class="slide level2">
<h2>Support Vector Machines</h2>
<ul>
<li><p>Powerful class of supervised learning algorithms used for classification and regression tasks</p></li>
<li><p>Particularly well-suited for high-dimensional datasets and problems with complex decision boundaries.</p></li>
</ul>
</section>
<section id="support-vector-machines-1" class="slide level2">
<h2>Support Vector Machines</h2>
<ul>
<li><p>SVM performs classification by finding the <strong>hyperplane</strong> that best separates the data into different classes</p></li>
<li><p>This hyperplane is chosen such that it maximizes the <strong>margin</strong> between the nearest data points of the two classes, which are called support vectors</p></li>
<li><p>Consider a binary classifier: <span class="math inline">\(Y\in\{-1,1\}\)</span></p></li>
<li><p><strong>Basic idea</strong>: Separate the space of features by hyperplanes into different regions such that the outcome is separated</p></li>
</ul>
</section>
<section id="support-vector-machines-2" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="hyperplanes">Hyperplanes</h4>
<ul>
<li>In a <span class="math inline">\(p\)</span>-dimensional space, a hyperplane is a flat affine subspace of dimension <span class="math inline">\(p-1\)</span></li>
</ul>
<p><span class="math display">\[\{x=(x_1,\dots,x_p): \beta_0+\beta_1x_1+\dots+ \beta_px_p=0\}.
\]</span></p>
<ul>
<li>If <span class="math inline">\(\beta_0+\beta_1x_1+\dots+ \beta_px_p&lt;0\)</span> then <span class="math inline">\(x\)</span> lies on one side and if <span class="math inline">\(\beta_0+\beta_1x_1+\dots+ \beta_px_p&gt;0\)</span> then <span class="math inline">\(x\)</span> lies the other side of the hyperplane</li>
</ul>
</section>
<section id="support-vector-machines-3" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="hyperplanes-1">Hyperplanes</h4>
<ul>
<li><p>Given a hyperplane <span class="math inline">\(\{x:f(x)=x\beta+\beta_0=0\}\)</span> the classification rule is defined as <span class="math display">\[
\hat{g}(x)=\text{sign}(f(x)).
\]</span></p></li>
<li><p><strong>Separable</strong> and <strong>non-separable</strong> cases</p></li>
</ul>
</section>
<section id="support-vector-machines-4" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="separable-case">Separable case</h4>
<div class="columns">
<div class="column" style="width:70%;">
<ul>
<li><p>For a given sample <span class="math inline">\((y_1,x_1),\dots,(y_n,x_n)\)</span> one can find a a hyperplane defined by <span class="math inline">\(f(x)\)</span> such that for all <span class="math inline">\(i\in\{1,\dots,n\}\)</span> we have <span class="math display">\[
y_if(x_i)&gt;0.
\]</span></p></li>
<li><p>It is possible to find the “<em>best</em>” hyperplane defined by <span class="math inline">\(\hat{f}(x)=x\hat{\beta}+\hat{\beta}_0\)</span> which separates the target variables on the sample</p></li>
</ul>
</div><div class="column" style="width:30%;">
<div id="2e0bef7b" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="Lecture_4_files/figure-revealjs/cell-6-output-1.png" width="260" height="209"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="support-vector-machines-5" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="separable-case-1">Separable case</h4>
<ul>
<li>Optimization problem: <span class="math display">\[
(\hat{\beta},\hat{\beta}_0)=\arg\max\limits_{\beta,\beta_0,\|\beta\|=1}M
\]</span> subject to <span class="math display">\[
y_i(x_i\beta+\beta_0)\ge M,\quad i=1,\dots,n.
\]</span></li>
</ul>
</section>
<section id="support-vector-machines-6" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="separable-case-2">Separable case</h4>
<ul>
<li>Optimization problem: Equivalent formulation <span class="math display">\[
(\hat{\beta},\hat{\beta}_0)=\arg\min\limits_{\beta,\beta_0}\|\beta\|_2^2
\]</span> with subject to <span class="math display">\[
y_i(x_i\beta+\beta_0)\ge 1,\quad i=1,\dots,n.
\]</span></li>
</ul>
</section>
<section id="support-vector-machines-7" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="non-separable-case">Non-separable case</h4>
<div class="columns">
<div class="column" style="width:70%;">
<ul>
<li><p><strong>Basic idea</strong>: Still maximize the <strong>margin</strong> <span class="math inline">\(M\)</span>, but allow for some points to be on the wrong side of the hyperplane</p></li>
<li><p>Define <strong>slack</strong> variables <span class="math inline">\(\xi=(\xi_1,\dots,\xi_n)\)</span> and modify the constraints <span class="math display">\[
y_i(x_i\beta+\beta_0)\ge M(1-\xi_i),\quad i=1,\dots,n
\]</span> with <span class="math inline">\(\xi_i\ge 0\)</span></p></li>
</ul>
</div><div class="column" style="width:30%;">
<div id="977636bf" class="cell" data-execution_count="6">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="Lecture_4_files/figure-revealjs/cell-7-output-1.png" width="271" height="209"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="support-vector-machines-8" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="non-separable-case-1">Non-separable case</h4>
<div class="columns">
<div class="column" style="width:70%;">
<ul>
<li>Missclassification occurs, if <span class="math inline">\(\xi_i&gt;1\)</span></li>
<li><span class="math inline">\(\xi_i\)</span> proportional amount by which the prediction <span class="math inline">\(f(x_i)\)</span> is on the wrong side of the margin.</li>
</ul>
</div><div class="column" style="width:30%;">
<div id="9f4c225f" class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="Lecture_4_files/figure-revealjs/cell-8-output-1.png" width="271" height="209"></p>
</figure>
</div>
</div>
</div>
</div></div>
<ul>
<li><strong>Solution</strong>: <strong>Soft-margin SVM classifier</strong></li>
</ul>
</section>
<section id="support-vector-machines-9" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="non-separable-case-2">Non-separable case</h4>
<ul>
<li>Soft-margin SVM classifier <span class="math display">\[
\hat{g}(x)=\text{sign}(x\hat{\beta}+\hat{\beta}_0)
\]</span> where <span class="math display">\[
(\hat{\beta},\hat{\beta}_0)=\arg\min\limits_{\beta,\beta_0}\|\beta\|_2^2+C\sum\limits_{i=1}^n\xi_i
\]</span> with subject to <span class="math display">\[
y_i(x_i\beta+\beta_0)\ge 1-\xi_i,\quad\xi_i\ge 0,\quad  i=1,\dots,n.
\]</span> The higher the tuning parameter <span class="math inline">\(C\)</span> the more misclassified points and points inside the margin are penalized.</li>
</ul>
</section>
<section id="support-vector-machines-10" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="kernel-trick">Kernel Trick</h4>
<ul>
<li><p><strong>Kernel trick</strong>: Implicitly map the input data into high-dimensional feature spaces</p></li>
<li><p>Effectively handle <strong>nonlinear</strong> relationships between features and not only rely on linear separation boundaries in the feature space</p></li>
<li><p><strong>Basic idea</strong>: One can transform the features to fit a linear classifier <span class="math display">\[
x=(x_1,\dots,x_p)\mapsto \varphi(x)=(\varphi_1(x),\dots,\varphi_m(x))
\]</span></p></li>
</ul>
</section>
<section id="support-vector-machines-11" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="kernel-trick-1">Kernel Trick</h4>
<ul>
<li><strong>Solution</strong>: Classification rule can be written as loss function with penalization: <span class="math display">\[
\hat{g}(x)=\text{sign}(x\hat{\beta}+\hat{\beta}_0)
\]</span> where <span class="math display">\[
(\hat{\beta},\hat{\beta}_0)=\arg\min\limits_{\beta,\beta_0}\sum\limits_{i=1}^n\underbrace{\big(1-y_i(x_i\beta+\beta_0)\big)_+}_{=L_{Hinge}\big(y_i(x_i\beta+\beta_0)\big)}+\frac{1}{C}\|\beta\|_2^2
\]</span> with respect to <span class="math display">\[
y_i(x_i\beta+\beta_0)\ge 1-\xi_i,\quad\xi_i\ge 0,\quad  i=1,\dots,n.
\]</span></li>
</ul>
</section>
<section id="support-vector-machines-12" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="kernel-trick-2">Kernel Trick</h4>
<ul>
<li><p>One can show that in the optimization the features <span class="math inline">\(x_i\)</span> only appear through their inner products <span class="math inline">\(\langle x_i,x_j\rangle\)</span></p></li>
<li><p>We just need to know the kernel functions <span class="math inline">\(k(x_i,x_j)=\langle \varphi(x_i),\varphi(x_j)\rangle\)</span></p></li>
<li><p>Examples:</p>
<ul>
<li><span class="math inline">\(d\)</span>-th degree polynomial kernel: <span class="math inline">\(k(x,x')=(1+\langle x,x'\rangle)^d\)</span></li>
<li>Radial basis functions (RBF): <span class="math inline">\(k(x,x')=\exp(-\gamma\|x-x'\|_2^2)\)</span></li>
</ul></li>
</ul>
</section>
<section id="support-vector-machines-13" class="slide level2">
<h2>Support Vector Machines</h2>
<h4 id="kernel-trick-3">Kernel Trick</h4>
<div id="79935e9b" class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="Lecture_4_files/figure-revealjs/cell-9-output-1.png" width="495" height="357"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="decision-trees" class="slide level2">
<h2>Decision Trees</h2>
<ul>
<li><p>The idea is to partition the regressor space <span class="math inline">\(\mathcal{X}\)</span> into rectangles, and then for each rectangle provide a predicted value.</p></li>
<li><p>Suppose we have <span class="math inline">\(n\)</span> observations <span class="math inline">\((Y_i,X_i)\)</span> for <span class="math inline">\(i=1,\dots,n\)</span> with <span class="math inline">\(X_i = (X_{i,1},\dots,X_{i,p})\)</span> and <span class="math inline">\(\mathcal{Y}=\{1,\dots,K\}\)</span>.<br> Given a partition of <span class="math inline">\(\mathcal{X}\)</span> into <span class="math inline">\(M\)</span> rectangles, called nodes, <span class="math inline">\(R_1,\dots,R_M\)</span> the decision tree is a prediction rule of the form <span class="math display">\[\hat{g}(x) = \sum\limits_{m=1}^M\hat{Y}_{R_m}1_{\{x\in R_m\}}.\]</span></p></li>
</ul>
</section>
<section id="decision-trees-1" class="slide level2">
<h2>Decision Trees</h2>
<ul>
<li><p>The prediction rule on each rectangle is defined by <span class="math display">\[\hat{Y}_{R_m} = \arg\max\limits_{y\in\mathcal{Y}}\frac{1}{n}\sum\limits_{i=1}^n 1_{\{X_i\in R_m\}}1_{\{Y_i= y\}}=\arg\max\limits_{y\in\mathcal{Y}}\frac{1}{n}\sum\limits_{i:X_i\in R_m}1_{\{Y_i= y\}} \]</span></p></li>
<li><p>How to determine the rectangles: We use <strong>recursive binary partitioning</strong> of the regressor space.</p></li>
<li><p>Divide the regressor space <span class="math inline">\(\mathcal{X}\)</span> into two sub-regions by choosing a regressor and a split point that archive the best improvement of impurity.</p></li>
<li><p>For a given rectangle <span class="math inline">\(R_m\)</span> let <span class="math inline">\(p^{(R_m)}=(p_1^{(R_m)},\dots,p_K^{(R_m)})\)</span>, where <span class="math inline">\(p_k^{(R_m)}\)</span>, <span class="math inline">\(k\in\{1,\dots,K\}\)</span>, is the fraction of target variables <span class="math inline">\(Y_i=k\)</span> in the rectangle <span class="math inline">\(R_m\)</span>.</p></li>
</ul>
</section>
<section id="decision-trees-2" class="slide level2">
<h2>Decision Trees</h2>
<ul>
<li><p>We call <span class="math display">\[I_{R_m}\big(p^{(R_m)}\big)=\sum\limits_{k=1}^K p_k^{(R_m)}\sum\limits_{l\neq k}^K p_l^{(R_m)}=1-\sum\limits_{k=1}^K \big(p_k^{(R_m)}\big)^2\]</span> the Gini impurity of <span class="math inline">\(R_m\)</span>.</p></li>
<li><p>We choose the split point that minimizes the average impurity: <span class="math display">\[\frac{1}{n}\sum\limits_{m=1}^M I_{R_m}\big(p^{(R_m)}\big)\]</span></p></li>
</ul>
</section>
<section id="decision-trees-3" class="slide level2">
<h2>Decision Trees</h2>
<div id="c5712f87" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href=""></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb8-2"><a href=""></a>decisiontree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span> <span class="dv">1</span>,random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb8-3"><a href=""></a>model <span class="op">=</span> decisiontree.fit(X, Y)</span>
<span id="cb8-4"><a href=""></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, np.mean(np.equal(model.predict(X_test),Y_test)) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.665625</code></pre>
</div>
</div>

<img data-src="figures/Example_1_decisiontree_split_1.png" class="r-stretch"></section>
<section id="decision-trees-4" class="slide level2">
<h2>Decision Trees</h2>
<div id="5880e6ec" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href=""></a><span class="im">from</span> sklearn.tree <span class="im">import</span> plot_tree</span>
<span id="cb10-2"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-3"><a href=""></a></span>
<span id="cb10-4"><a href=""></a><span class="co"># Plot the decision tree</span></span>
<span id="cb10-5"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb10-6"><a href=""></a>plot_tree(model, filled<span class="op">=</span><span class="va">True</span>, feature_names <span class="op">=</span> [<span class="st">"X1"</span>, <span class="st">"X2"</span>], class_names <span class="op">=</span> [<span class="st">"0"</span>, <span class="st">"1"</span>, <span class="st">"2"</span>])</span>
<span id="cb10-7"><a href=""></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="Lecture_4_files/figure-revealjs/cell-11-output-1.png" width="614" height="315"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="decision-trees-5" class="slide level2">
<h2>Decision Trees</h2>
<ul>
<li><p>Now we repeat this procedure for each sub-region and obtain four sub-regions. We continue this until the desired number of steps is reached or a minimal number of observations per rectangle, called minimal node size, is reached.</p></li>
<li><p>Given the final partition <span class="math inline">\(R_1,\dots ,R_M\)</span> the prediction rule is equivalent to <span class="math display">\[\hat{Y}_{R_m} =\arg\max\limits_{k\in\{1,\dots,K\}}p_k^{(R_m)}\]</span> For each rectangle we predict the value with the highest fraction/probability.</p></li>
</ul>
</section>
<section id="decision-trees-6" class="slide level2">
<h2>Decision Trees</h2>
<div id="4bcaa866" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href=""></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb11-2"><a href=""></a>maxdepth <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb11-3"><a href=""></a>rand <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-4"><a href=""></a>decisiontree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span> maxdepth,random_state<span class="op">=</span>rand)</span>
<span id="cb11-5"><a href=""></a>model <span class="op">=</span> decisiontree.fit(X, Y)</span>
<span id="cb11-6"><a href=""></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, np.mean(np.equal(model.predict(X_test),Y_test)) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.815625</code></pre>
</div>
</div>
</section>
<section id="decision-trees-7" class="slide level2">
<h2>Decision Trees</h2>

<img data-src="figures/Example_1_decisiontree_split_2.png" class="r-stretch"></section>
<section id="decision-trees-8" class="slide level2">
<h2>Decision Trees</h2>
<div id="55c62688" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href=""></a><span class="co"># Plot the decision tree</span></span>
<span id="cb13-2"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb13-3"><a href=""></a>plot_tree(model, filled<span class="op">=</span><span class="va">True</span>, feature_names <span class="op">=</span> [<span class="st">"X1"</span>, <span class="st">"X2"</span>], class_names <span class="op">=</span> [<span class="st">"0"</span>, <span class="st">"1"</span>, <span class="st">"2"</span>])</span>
<span id="cb13-4"><a href=""></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="Lecture_4_files/figure-revealjs/cell-13-output-1.png" width="614" height="315"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="decision-trees-9" class="slide level2">
<h2>Decision Trees</h2>
<div id="a7fa5a55" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href=""></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb14-2"><a href=""></a>maxdepth <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb14-3"><a href=""></a>rand <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-4"><a href=""></a>decisiontree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span> maxdepth,random_state<span class="op">=</span>rand)</span>
<span id="cb14-5"><a href=""></a>model <span class="op">=</span> decisiontree.fit(X, Y)</span>
<span id="cb14-6"><a href=""></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, np.mean(np.equal(model.predict(X_test),Y_test)) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.828125</code></pre>
</div>
</div>
</section>
<section id="decision-trees-10" class="slide level2">
<h2>Decision Trees</h2>

<img data-src="figures/Example_1_decisiontree_split_3.png" class="r-stretch"></section>
<section id="decision-trees-11" class="slide level2">
<h2>Decision Trees</h2>
<div id="344bb382" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href=""></a><span class="im">from</span> sklearn.tree <span class="im">import</span> plot_tree</span>
<span id="cb16-2"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-3"><a href=""></a></span>
<span id="cb16-4"><a href=""></a><span class="co"># Plot the decision tree</span></span>
<span id="cb16-5"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb16-6"><a href=""></a>plot_tree(model, filled<span class="op">=</span><span class="va">True</span>, feature_names <span class="op">=</span> [<span class="st">"X1"</span>, <span class="st">"X2"</span>], class_names <span class="op">=</span> [<span class="st">"0"</span>, <span class="st">"1"</span>, <span class="st">"2"</span>])</span>
<span id="cb16-7"><a href=""></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="Lecture_4_files/figure-revealjs/cell-15-output-1.png" width="614" height="315"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="decision-trees-12" class="slide level2">
<h2>Decision Trees</h2>
<h4 id="problems">Problems</h4>
<ul>
<li>If we grow the tree to deep our estimate performs well on the sample, but does not generalize well (overfitting).</li>
</ul>
<p><span class="math inline">\(\Rightarrow\)</span> We need to control maximal depth or the node size.<br></p>
<ul>
<li>Due to the splitting rule small variations in the sample might result in a completely different tree being build (high variance).</li>
</ul>
</section>
<section id="decision-trees-13" class="slide level2">
<h2>Decision Trees</h2>
<h4 id="problems-1">Problems</h4>
<div id="c95bcf66" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href=""></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb17-2"><a href=""></a>maxdepth <span class="op">=</span> <span class="dv">40</span></span>
<span id="cb17-3"><a href=""></a>rand <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-4"><a href=""></a>decisiontree <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span> maxdepth,random_state<span class="op">=</span>rand)</span>
<span id="cb17-5"><a href=""></a>model <span class="op">=</span> decisiontree.fit(X, Y)</span>
<span id="cb17-6"><a href=""></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, np.mean(np.equal(model.predict(X_test),Y_test)) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.803125</code></pre>
</div>
</div>
</section>
<section id="decision-trees-14" class="slide level2">
<h2>Decision Trees</h2>
<h4 id="problems-2">Problems</h4>
<div id="fed0c865" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href=""></a><span class="im">from</span> sklearn.tree <span class="im">import</span> plot_tree</span>
<span id="cb19-2"><a href=""></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-3"><a href=""></a></span>
<span id="cb19-4"><a href=""></a><span class="co"># Plot the decision tree</span></span>
<span id="cb19-5"><a href=""></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb19-6"><a href=""></a>plot_tree(model, filled<span class="op">=</span><span class="va">True</span>, feature_names <span class="op">=</span> [<span class="st">"X1"</span>, <span class="st">"X2"</span>], class_names <span class="op">=</span> [<span class="st">"0"</span>, <span class="st">"1"</span>, <span class="st">"2"</span>])</span>
<span id="cb19-7"><a href=""></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><img data-src="Lecture_4_files/figure-revealjs/cell-17-output-1.png" width="614" height="315"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="random-forest-classifiers-and-bagging" class="slide level2">
<h2>Random Forest Classifiers and Bagging</h2>
<ul>
<li><p>Even if we control the maximal depth or the node size, one single decision tree rarely gives satisfactory performance.</p></li>
<li><p>The idea of Random Forests is to grow many different deep trees and then aggregate the predictions of each tree to a new combined prediction.</p></li>
<li><p>The trees are grown over different bootstrap samples (quasi copies). Each tree is grown deep to keep the approximation error low and the averaging is meant to reduce the noisiness of individual trees.</p></li>
</ul>
</section>
<section id="random-forest-classifiers-and-bagging-1" class="slide level2">
<h2>Random Forest Classifiers and Bagging</h2>
<h4 id="bagging">Bagging:</h4>
<ol type="1">
<li>Draw <span class="math inline">\(B\)</span> bootstrap samples from <span class="math inline">\((Y_1,X_1)\dots,(Y_n,X_n)\)</span>.</li>
<li>For each bootstrap sample <span class="math inline">\(b\in\{1,\dots,B\}\)</span> grow a deep decision tree and obtain a partition <span class="math inline">\(R_1^{(b)},\dots,R_{M_b}^{(b)}\)</span> with fractions <span class="math display">\[p^{(R_m^{(b)})}=\big(p_1^{(R_m^{(b)})},\dots,p_K^{(R_m^{(b)})}\big)\]</span> for each rectangle.</li>
<li>For each <span class="math inline">\(x\in\mathcal{X}\)</span> and bootstrap sample <span class="math inline">\(b\)</span> we obtain probabilities for each outcome <span class="math inline">\(k\)</span> <span class="math display">\[p^{(b)}_k(x)=\sum\limits_{m=1}^{M_b}p_k^{(R_m^{(b)})}1_{\{x\in R_m^{(b)}\}}.\]</span></li>
</ol>
</section>
<section id="random-forest-classifiers-and-bagging-2" class="slide level2">
<h2>Random Forest Classifiers and Bagging</h2>
<h4 id="bagging-continued">Bagging (continued):</h4>
<ol start="5" type="1">
<li>Output the prediction rule: <span class="math display">\[\hat{g}(x) = \arg\max\limits_{k\in\{1,\dots,K\}}\frac{1}{B}\sum\limits_{b=1}^B p^{(b)}_k(x)\]</span></li>
</ol>
</section>
<section id="random-forest-classifiers-and-bagging-3" class="slide level2">
<h2>Random Forest Classifiers and Bagging</h2>
<p>From Bagging to Random Forests:</p>
<ul>
<li>The key underlying idea is that the trees are grown deep to keep the approximation error low, and averaging is meant to reduce the noisyness of individual trees.</li>
<li>The procedure of averaging noisy prediction rules over the bootstrap samples is called Bootstrap Aggregation or Bagging.</li>
<li>There are many modifications and other tunig parameters of this method.</li>
</ul>
</section>
<section id="random-forest-classifiers-and-bagging-4" class="slide level2">
<h2>Random Forest Classifiers and Bagging</h2>
<ul>
<li>One very important modification is the use of additional randomization to “decorrelate” the trees: Instead of choosing the best split on all variables we just split on a random subset of the regressors <span class="math inline">\(\Rightarrow\)</span> <strong>Random Forest</strong></li>
</ul>
<div id="329cc917" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href=""></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb20-2"><a href=""></a>randforest <span class="op">=</span> RandomForestClassifier(max_depth<span class="op">=</span><span class="dv">4</span>,random_state<span class="op">=</span><span class="dv">0</span>, n_estimators <span class="op">=</span> <span class="dv">100</span>)</span>
<span id="cb20-3"><a href=""></a>model <span class="op">=</span> randforest.fit(X, Y)</span>
<span id="cb20-4"><a href=""></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, np.mean(np.equal(model.predict(X_test),Y_test)) )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.834375</code></pre>
</div>
</div>
</section>
<section id="random-forest-classifiers-and-bagging-5" class="slide level2">
<h2>Random Forest Classifiers and Bagging</h2>

<img data-src="figures/Example_1_rndforest.png" class="r-stretch"><div class="quarto-auto-generated-content">
<div class="footer footer-default">
<p><a href="https://alexandragibbon.github.io/StatProg-HHU/">Topics in Econometrics and Data Science</a></p>
</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="Lecture_4_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="Lecture_4_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="Lecture_4_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="Lecture_4_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="Lecture_4_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="Lecture_4_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="Lecture_4_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="Lecture_4_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="Lecture_4_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="Lecture_4_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="Lecture_4_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"boardmarkerWidth":5,"theme":"chalkboard"},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>