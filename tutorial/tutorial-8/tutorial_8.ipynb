{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Topics in Econometrics and Data Science: Tutorial 8\"\n",
    "\n",
    "---\n",
    "\n",
    "#### General Note\n",
    "\n",
    "You will very likely find the solution to these exercises online. We, however, strongly encourage you to work on these exercises without doing so. Understanding someone elseâ€™s solution is very different from coming up with your own. Use the lecture notes and try to solve the exercises independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 cont'd: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Linear Regression: Inference II - Simulation for the Linear Regression Model (OLS)\n",
    "\n",
    "Let us consider a univariate regression model \n",
    "\n",
    "$$Y = X\\beta + \\varepsilon,$$\n",
    "where $Y$ is the outcome variable and $X$ is a regressor. $\\varepsilon$ is drawn from a Normal distribution with variance $\\mu = 0$ and $\\sigma = 1$ and independent from $X$. We are interested in inference on $\\beta$. \n",
    "\n",
    "In this exercise, we simulate data according to the regression model above in order to provide evidence in favor of the theoretical results we learned in the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A)\n",
    "\n",
    "Set up a data generating process (DGP) according to the regression model above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function with inputs  $\\beta$ and $n$ and outputs $Y$ and $X$. Generate $X$ as $X \\sim_{i.i.d} N(0,1)$. \\\n",
    "\\\n",
    "**Hint:** You can use [`np.random.normal`](https://numpy.org/doc/2.0/reference/random/generated/numpy.random.normal.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a function for the DGP\n",
    "def DGP(beta, n):\n",
    "\n",
    "    \n",
    "    return Y,X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use your function to generate $n=20$ observations for $Y$ and $X$ and use $\\beta = 1$ in your example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try if it works\n",
    "n = 20\n",
    "beta = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run a linear regression based on your generated data in part B. \\\n",
    "\\\n",
    "**Hint:** Use the package [`statsmodels`](https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Run a linear regression \n",
    "olssim = sm.OLS(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) \n",
    "\n",
    "Set up a simulation study to estimate the *Bias* and *Standard Error* of $\\hat{\\beta}$. How do the results change if $n$ increases, e.g. $n=10, 20, 30, 40, 50, 100, 200, 400$? Illustrate your results with an appropriate graphic. Do your result support the claim that the OLS estimator is an unbiased estimator? What can you say about estimation uncertainty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias \n",
    "Bias = beta - olssim.params[0]\n",
    "SE = olssim.bse[0]\n",
    "\n",
    "print(\"Bias\", Bias)\n",
    "print(\"SE\", SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with a lopp for a varying number of observations \n",
    "beta = 1\n",
    "nobs = [10, 20, 30, 40, 50, 100, 200, 400]\n",
    "\n",
    "# We need to declare objects to save the results\n",
    "Bias = np.zeros(len(nobs))\n",
    "SE = np.zeros(len(nobs))\n",
    "Estim = np.zeros(len(nobs))\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "for i in range(0,len(nobs)):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C)\n",
    "\n",
    "Repeat the simulation from before $R=100$ times and report the average results (i.e. the average *Bias*, *Standard Error* and $\\hat{\\beta}$ *estimate* over the $R$ repetitions). Illustrate your results with an appropriate graphic.\n",
    "\n",
    "**Hint:** Write a function that executes the estimation from before automatically and that repeats the calculations $R$ times. The inputs of this function are $n$ and $R$ and the outpus are the average *Bias*, the average *Standard Error* and the average $\\hat{\\beta}$ *estimate*.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: nobs, nrep\n",
    "# Given a number of observation, we want to repeat the simulation R times\n",
    "# Output: mean Bias, SE and Estimates\n",
    "\n",
    "def SIM(n, R):\n",
    "    \n",
    "    \n",
    "    return mBias, mSE, mEstim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) \n",
    "\n",
    "In the lecture, we have learned that the t-statistic $t$ for the regression coefficient $\\beta$ is asymptotically normal if $n$ is large. Use the simulation study to provide evidence that in the setting above it holds that:\n",
    "    $$\\sqrt{n}(\\hat{\\beta} - \\beta) \\xrightarrow[]{d} N(0,1)$$\n",
    "**Hint:** Repeat the simulation from above. Now, we need to save the $\\hat{\\beta}$ so that we can compute $\\sqrt{n}(\\hat{\\beta}-\\beta)$. For this, write a new function similiar to the one in part C. The inputs are $n$ and $R$ and the output is an array (of length $R$) that contains the $\\hat{\\beta}$. Illustrate the results by generating a bar plot similar to that in Lecture 2 (slide 23).\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the SIM Function\n",
    "\n",
    "def SIM2(n, R):\n",
    "    \n",
    "\n",
    "            \n",
    "    return Estim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
