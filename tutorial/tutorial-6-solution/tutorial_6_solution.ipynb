{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Topics in Econometrics and Data Science: Tutorial 6\"\n",
    "\n",
    "---\n",
    "\n",
    "#### General Note\n",
    "\n",
    "You will very likely find the solution to these exercises online. We, however, strongly encourage you to work on these exercises without doing so. Understanding someone elseâ€™s solution is very different from coming up with your own. Use the lecture notes and try to solve the exercises independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 cont'd: Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Hypothesis Testing (II)\n",
    "Now we want to test whether the proportion (probability of success) in a group equals a certain given value.\n",
    "\n",
    "1. Use `help(stats.binomtest)` to make yourself familiar with the [`binomtest`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binomtest.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "#help(stats.binomtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A poll taken in $2003$ among $200$ Europeans found that only $16\\%$ favored the policies of the United States. Perform a test of significance to see whether this is significantly different from the $50\\%$ proportion of Americans in favor of these policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinomTestResult(k=32, n=200, alternative='two-sided', statistic=0.16, pvalue=1.818080038171794e-23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.binomtest(32,200,0.5) # two-sided test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. A new drug therapy is tested. Of $50$ patients in the study, $40$ had no recurrence in their illness after $18$ months. With no drug therapy, the expected percentage of no recurrence would have been $75\\%$. Does the data support the hypothesis that this percentage has increased? What is the $p$-value? Why is useful to consider a one-sided test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinomTestResult(k=40, n=50, alternative='two-sided', statistic=0.8, pvalue=0.514121165666749)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.binomtest(40,50,0.75) # two-sided test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinomTestResult(k=40, n=50, alternative='greater', statistic=0.8, pvalue=0.2622023101895092)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.binomtest(40,50,0.75, alternative = \"greater\") # One-sided hypothesis\n",
    "\n",
    "# We want to know whether the drug therapy increases the proportion of patients with no recurrence. \n",
    "# A two-sided test would also consider the possibility of a decrease, which is not relevant here. \n",
    "# A one-sided test is more powerful for detecting an increase in the percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Bootstrap\n",
    "Load the [`lightbulb_lifetime.csv`](https://alexandragibbon.github.io/StatProg-HHU/data/lightbulb_lifetime.csv) data, which contains a (simulated) sample of lifespans of lightbulbs measured in hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572.691989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.268241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>797.757928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>571.500317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>545.361518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0  572.691989\n",
       "1   26.268241\n",
       "2  797.757928\n",
       "3  571.500317\n",
       "4  545.361518"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "path = \"C:/Users/DICE/Dropbox/Statistical Programming/StatProg-HHU-oct24\"\n",
    "os.chdir(path)\n",
    "lightbulb_lifetime = pd.read_csv('data/lightbulb_lifetime.csv', sep=';', na_values=\".\")\n",
    "lightbulb_lifetime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Estimate the median lifetime of a lightbulb.\\\n",
    "**Hint:** you can use `.values` to convert pandas dataframes into arrays and `.flatten()` to create vectors from arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596.2420166828964\n"
     ]
    }
   ],
   "source": [
    "lightbulb_lifetime = lightbulb_lifetime.values\n",
    "lightbulb_lifetime = lightbulb_lifetime.flatten()\n",
    "med = np.median(lightbulb_lifetime)\n",
    "print(med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The sample median is an asymptotically normal distributed estimator for the median. Try to estimate the variance of the sample median with bootstrap.  \n",
    "**Hint**: Use `np.random.choice()`, additionally `np.empty()` could be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "n = 200\n",
    "B = 500\n",
    "alpha = 0.05\n",
    "quantile = stats.norm.ppf(q = 1-alpha/2)\n",
    "bootstrap_sample1 = np.empty((B, n))\n",
    "for j in range(B):\n",
    "     bootstrap_sample1[j] = np.random.choice(lightbulb_lifetime,n)\n",
    "#or even better\n",
    "bootstrap_sample = np.random.choice(lightbulb_lifetime,(B,n))\n",
    "bootstrap_est = np.median(bootstrap_sample,axis =1)\n",
    "#print(bootstrap_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800.3657745531796\n",
      "(492.5236971543423, 699.9603362114506)\n",
      "[538.31503576 706.09709512]\n"
     ]
    }
   ],
   "source": [
    "var_est = np.var(bootstrap_est)\n",
    "print(var_est)\n",
    "# using the asymptotic normal distribution\n",
    "confidence_interval1 = (med - np.sqrt(var_est)*quantile,med + np.sqrt(var_est)*quantile)\n",
    "# using the sample quantiles for the estimator\n",
    "confidence_interval2 = np.quantile(bootstrap_est, (alpha/2,1-alpha/2))\n",
    "print(confidence_interval1)\n",
    "print(confidence_interval2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Show with a simulation that your confidence interval is able to asymptotically satisfy the confidence level. Use standard normal distributed and exponential ( with parameter 0.01) distributed random variables in your simulation.  \n",
    "**Hint**:`np.random.normal()` and `np.random.exponential()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here's the second variant (working on pandas DataFrames): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572.691989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.268241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>797.757928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>571.500317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>545.361518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0  572.691989\n",
       "1   26.268241\n",
       "2  797.757928\n",
       "3  571.500317\n",
       "4  545.361518"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "lightbulb_lifetime = pd.read_csv('data/lightbulb_lifetime.csv', sep=';', na_values=\".\")\n",
    "lightbulb_lifetime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596.2420166828964\n"
     ]
    }
   ],
   "source": [
    "med = np.median(lightbulb_lifetime)\n",
    "print(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "n = 200\n",
    "B = 500\n",
    "alpha = 0.05\n",
    "quantile = stats.norm.ppf(q = 1-alpha/2)\n",
    "\n",
    "bootstrap_est = np.empty(B)\n",
    "\n",
    "for j in range(B):\n",
    "    indx = np.random.randint(n, size=n)\n",
    "    bootstrap_est[j] = np.median(lightbulb_lifetime.iloc[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492.71134162812444, 699.7726917376684)\n",
      "[537.36395253 703.68082448]\n"
     ]
    }
   ],
   "source": [
    "var_est = np.var(bootstrap_est)\n",
    "# using the asymptotic normal distribution\n",
    "confidence_interval1 = (med - np.sqrt(var_est)*quantile,med + np.sqrt(var_est)*quantile)\n",
    "\n",
    "# using the sample quantiles for the estimator\n",
    "confidence_interval2 = np.quantile(bootstrap_est, (alpha/2, 1-alpha/2))\n",
    "\n",
    "print(confidence_interval1)\n",
    "print(confidence_interval2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing a one-sided confidence interval (here only calculating the lower bound, since the upper bound is $\\infty$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509.3563352582254\n",
      "545.3342596272213\n"
     ]
    }
   ],
   "source": [
    "quantile2  = stats.norm.ppf(q = 1-alpha)\n",
    "# using the asymptotic normal distribution\n",
    "lower_bound1 = med - np.sqrt(var_est)*quantile2\n",
    "# using the sample quantiles for the estimator\n",
    "lower_bound2 = np.percentile(bootstrap_est, (5))\n",
    "print(lower_bound1)\n",
    "print(lower_bound2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n = 500\n",
    "B = 200\n",
    "l = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of rejected null hypothesis: 6.22\n"
     ]
    }
   ],
   "source": [
    "mu = 0\n",
    "sigma = 1\n",
    "#the true median is zero\n",
    "\n",
    "alpha = 0.05\n",
    "quantile = stats.norm.ppf(q = 1-alpha/2)\n",
    "count = 0\n",
    "for i in range(1, l):\n",
    "    sample = np.random.normal(mu, sigma, n)\n",
    "    med_est = np.median(sample)\n",
    "    bootstrap_sample = np.random.choice(sample,(B,n))\n",
    "    bootstrap_est = np.median(bootstrap_sample,axis =1)\n",
    "    var_est = np.var(bootstrap_est)\n",
    "    confidence_interval1 = (med_est - np.sqrt(var_est)*quantile,med_est + np.sqrt(var_est)*quantile)\n",
    "    if confidence_interval1[0] > 0 or confidence_interval1[1] < 0:\n",
    "        count += 1\n",
    "print(\"percentage of rejected null hypothesis:\", count/l*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of rejected null hypothesis: 6.0600000000000005\n"
     ]
    }
   ],
   "source": [
    "lam = 100\n",
    "med = np.log(2)*100 #true median\n",
    "\n",
    "alpha = 0.05\n",
    "quantile = stats.norm.ppf(q = 1-alpha/2)\n",
    "count = 0\n",
    "for i in range(1, l):\n",
    "    sample = np.random.exponential(lam, n)    \n",
    "    med_est = np.median(sample)\n",
    "    bootstrap_sample = np.random.choice(sample,(B,n))\n",
    "    bootstrap_est = np.median(bootstrap_sample,axis =1)\n",
    "    var_est = np.var(bootstrap_est)\n",
    "    confidence_interval1 = (med_est - np.sqrt(var_est)*quantile,med_est + np.sqrt(var_est)*quantile)\n",
    "    if confidence_interval1[0] > med or confidence_interval1[1] < med:\n",
    "        count += 1\n",
    "print(\"percentage of rejected null hypothesis:\", count/l*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
